# knn - K近邻算法

1、	K近邻算法，即是给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的K个实例，这K个实例的多数属于某个类，就把该输入实例分类到这个类中。

	【图1】

	根据图来解释

	某个点半径范围内包含某个分类的点最多

2、	用途：用于分类和回归的问题

以上就是核心思想

下面是具体怎么做

3、 选取k值，计算距离，判断分类【图1】

4问题：k值不同，结果不同，k值如何选取。

k值过小？过度拟合，模型复杂，容易变成噪声
k值过大？模型过简单，忽略训练集的有用信息，比如距离，度量

如何选取K值
先选取小的，交叉验证，实验调参。

如何交叉验证？？https://blog.csdn.net/sundreamoon/article/details/79874764
比较K个训练集的分类率

5 问题：距离选取

欧式距离

6 特征归一化

维度不同，欧式距离的缺点

某个维度数量过大导致分类出错

在计算欧式距离加上归一化公式，距离转到0-1之间

更好的归一化，讲不同维度的计量方式影响消除

马氏距离
概念讲解
就是在欧几里得距离乘以一个协方差矩阵
协方差是什么
协方差矩阵是什么

为什么用马氏距离

可以作为分类噪点的发现，评判，因为可以计算相关度。




7 计算优化

剪辑近邻法
压缩近邻法

8 几种常见的距离公式的介绍

余弦相似度
欧几里得公式乘以一个夹角余弦
相似用户推荐，反馈，问答相似度关联


9 回归的knn
https://www.cnblogs.com/pythoner6833/p/9296035.html